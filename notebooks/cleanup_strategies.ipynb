{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "abd72a52-e46a-4604-9c34-8a8cd6c9f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ae/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ae/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ae/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cleaner\n",
    "import re\n",
    "import torch\n",
    "import nltk\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stopwords_en = stopwords.words('english')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "bert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72bea773-a1fc-43cd-9604-112da121f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = [\n",
    "    'C', 'C#', 'C++', 'Dart', 'Elixir', 'Go', 'JSON', 'Java', \n",
    "    'Javascript', 'Julia', 'Kotlin', 'Markdown', 'Ruby', 'Rust', 'Python'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "112de1f3-472f-4913-b505-9681eb47673d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Markdown/000001.md</td>\n",
       "      <td>Markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Markdown/000004.md</td>\n",
       "      <td>Markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Markdown/000005.md</td>\n",
       "      <td>Markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Markdown/000006.md</td>\n",
       "      <td>Markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>JSON/000007.json</td>\n",
       "      <td>JSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           file_path  language\n",
       "0   1  Markdown/000001.md  Markdown\n",
       "3   4  Markdown/000004.md  Markdown\n",
       "4   5  Markdown/000005.md  Markdown\n",
       "5   6  Markdown/000006.md  Markdown\n",
       "6   7    JSON/000007.json      JSON"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/ae/repos/archivos/dataset.csv\")\n",
    "df = df[df['language'].isin(TARGET)]\n",
    "\n",
    "del df['file_size']\n",
    "del df['line_count']\n",
    "del df['extension']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a0b5314-4b06-4e7d-b819-60a57229869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_content(path, origin):\n",
    "    path = origin + \"/\" + path\n",
    "    \n",
    "    file = open(path, 'rb')\n",
    "    contents = file.read().decode(errors = \"ignore\")\n",
    "    file.close()\n",
    "    \n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a0f34ef-a311-463c-abbe-c584ff16309c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>language</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Markdown/000001.md</td>\n",
       "      <td>Markdown</td>\n",
       "      <td># Contributing\\n\\n| Component            | Bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Markdown/000004.md</td>\n",
       "      <td>Markdown</td>\n",
       "      <td># Azure SDK for .NET\\n\\n[![Packages](https://i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Markdown/000005.md</td>\n",
       "      <td>Markdown</td>\n",
       "      <td>&lt;!-- BEGIN MICROSOFT SECURITY.MD V0.0.5 BLOCK ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Markdown/000006.md</td>\n",
       "      <td>Markdown</td>\n",
       "      <td># Support\\n\\n## How to file issues and get hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>JSON/000007.json</td>\n",
       "      <td>JSON</td>\n",
       "      <td>{\\n  \"$schema\": \"https://raw.githubusercontent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           file_path  language  \\\n",
       "0   1  Markdown/000001.md  Markdown   \n",
       "3   4  Markdown/000004.md  Markdown   \n",
       "4   5  Markdown/000005.md  Markdown   \n",
       "5   6  Markdown/000006.md  Markdown   \n",
       "6   7    JSON/000007.json      JSON   \n",
       "\n",
       "                                              source  \n",
       "0  # Contributing\\n\\n| Component            | Bui...  \n",
       "3  # Azure SDK for .NET\\n\\n[![Packages](https://i...  \n",
       "4  <!-- BEGIN MICROSOFT SECURITY.MD V0.0.5 BLOCK ...  \n",
       "5  # Support\\n\\n## How to file issues and get hel...  \n",
       "6  {\\n  \"$schema\": \"https://raw.githubusercontent...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'] = df['file_path'].apply(lambda x: read_content(x, \"/home/ae/repos/archivos/dataset\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d37bccbe-3c4d-4e7a-a871-d5f5e245c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "df_dirty = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e01d530f-d081-4ed5-be14-3f773cd59878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments(contents, language) -> str:\n",
    "    delimiters = cleaner.lang(language)\n",
    "    \n",
    "    if delimiters is not None:\n",
    "        contents = cleaner.string(contents, *delimiters)\n",
    "        \n",
    "    return contents\n",
    "\n",
    "def clean_extras(contents) -> str:\n",
    "    contents = re.sub(r'[\\r]', '', contents)\n",
    "    contents = re.sub(r'\\w{15,}', '', contents)\n",
    "    contents = re.sub('[\\n]{2,}', '\\n', contents)\n",
    "    contents = re.sub('[\\t]{2,}', '\\t', contents)\n",
    "    contents = re.sub(r'[ ]+', ' ', contents)\n",
    "\n",
    "    contents = \"\\n\".join([line for line in contents.splitlines() if len(line.strip()) != 0])\n",
    "\n",
    "    return contents\n",
    "\n",
    "def tokenize(source: str) -> torch.Tensor:\n",
    "    tokens = bert_tokenizer.tokenize(source)\n",
    "    lemmas = (lemmatizer.lemmatize(token) for token in tokens if token not in stopwords_en)\n",
    "    return torch.tensor(bert_tokenizer.convert_tokens_to_ids(lemmas))[None,:]\n",
    "    \n",
    "\n",
    "def vectorize(tokens: torch.Tensor) -> np.ndarray:    \n",
    "    embed = bert_model(tokens[1])\n",
    "    \n",
    "    return embed.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac9d4f0a-7fd4-49e4-92db-0a67bdb02e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>language</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Markdown/000001.md</td>\n",
       "      <td>Markdown</td>\n",
       "      <td># Contributing\\n\\n| Component            | Bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Markdown/000004.md</td>\n",
       "      <td>Markdown</td>\n",
       "      <td># Azure SDK for .NET\\n\\n[![Packages](https://i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Markdown/000005.md</td>\n",
       "      <td>Markdown</td>\n",
       "      <td>\\n\\n## Security\\n\\nMicrosoft takes the securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Markdown/000006.md</td>\n",
       "      <td>Markdown</td>\n",
       "      <td># Support\\n\\n## How to file issues and get hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>JSON/000007.json</td>\n",
       "      <td>JSON</td>\n",
       "      <td>{\\n  \"$schema\": \"https:\\n  \"meta\": {\\n    \"aut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           file_path  language  \\\n",
       "0   1  Markdown/000001.md  Markdown   \n",
       "3   4  Markdown/000004.md  Markdown   \n",
       "4   5  Markdown/000005.md  Markdown   \n",
       "5   6  Markdown/000006.md  Markdown   \n",
       "6   7    JSON/000007.json      JSON   \n",
       "\n",
       "                                              source  \n",
       "0  # Contributing\\n\\n| Component            | Bui...  \n",
       "3  # Azure SDK for .NET\\n\\n[![Packages](https://i...  \n",
       "4  \\n\\n## Security\\n\\nMicrosoft takes the securit...  \n",
       "5  # Support\\n\\n## How to file issues and get hel...  \n",
       "6  {\\n  \"$schema\": \"https:\\n  \"meta\": {\\n    \"aut...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['source'] = df_clean.apply(lambda r: clean_comments(r.source, r.language), axis=1)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9569ccc5-a454-4fb2-ad88-7f6b7e86a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['source'] = df_clean['source'].apply(clean_extras)\n",
    "df_dirty['source'] = df_dirty['source'].apply(clean_extras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "891ad355-d170-47fb-9309-91c2c5ec18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_code_into_chunks(code, max_chars):\n",
    "    lines = code.split('\\n')\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        if current_length + len(line) + 1 > max_chars:\n",
    "            chunks.append('\\n'.join(current_chunk))\n",
    "            current_chunk = [line]\n",
    "            current_length = len(line) + 1  # +1 for the newline character\n",
    "        else:\n",
    "            current_chunk.append(line)\n",
    "            current_length += len(line) + 1  # +1 for the newline character\n",
    "    \n",
    "    # Add the last chunk\n",
    "    # if current_chunk:\n",
    "        # chunks.append('\\n'.join(current_chunk))\n",
    "    \n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "847e885c-fb11-4983-8b92-5798239d3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_chunk_entries(df: pd.DataFrame, ENTRIES = 3000, MAX_CHARS = 512) -> pd.DataFrame:\n",
    "    status = {}\n",
    "    bufs = {}\n",
    "    \n",
    "    for lang in list(TARGET):\n",
    "        status[lang] = 0\n",
    "    \n",
    "    new_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        language = row.language\n",
    "        \n",
    "        if status[language] < ENTRIES:\n",
    "            for chunk in split_code_into_chunks(row.source, MAX_CHARS):\n",
    "                if MAX_CHARS * 0.8 >= float(len(chunk)) and status[language] < ENTRIES:\n",
    "                    new_rows.append({'language': language, 'source': chunk})\n",
    "                    status[language] += 1\n",
    "    \n",
    "    return pd.DataFrame(new_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f97a2658-5075-4e12-83f1-abc3aebbd633",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_chunks = gen_chunk_entries(df_clean, 500)\n",
    "df_dirty_chunks = gen_chunk_entries(df_dirty, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b6adddb0-ade4-4156-8eca-d3c2930ba336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 3830/3830 [00:03<00:00, 1005.42it/s]\n",
      "100%|█████████████████████████| 4186/4186 [00:04<00:00, 928.47it/s]\n"
     ]
    }
   ],
   "source": [
    "df_clean_chunks['tokens'] = df_clean_chunks['source'].progress_apply(tokenize)\n",
    "df_dirty_chunks['tokens'] = df_dirty_chunks['source'].progress_apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "91020e69-6749-4ca5-904c-bd83da7c8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_chunks = df_clean_chunks[df_clean_chunks['tokens'].apply(lambda x: x.shape) != (1, 0)]\n",
    "df_dirty_chunks = df_dirty_chunks[df_dirty_chunks['tokens'].apply(lambda x: x.shape) != (1, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "796d49c6-28df-40be-b2ab-9fc9b195dd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                            | 1/3809 [00:00<00:05, 646.87it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_clean_chunks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_clean_chunks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectorize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_dirty_chunks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_dirty_chunks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprogress_apply(vectorize)\n",
      "File \u001b[0;32m~/repos/proyecto-pln/.venv/lib/python3.12/site-packages/tqdm/std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/repos/proyecto-pln/.venv/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/proyecto-pln/.venv/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/proyecto-pln/.venv/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/repos/proyecto-pln/.venv/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/proyecto-pln/.venv/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/repos/proyecto-pln/.venv/lib/python3.12/site-packages/tqdm/std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[70], line 27\u001b[0m, in \u001b[0;36mvectorize\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvectorize\u001b[39m(tokens: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:    \n\u001b[0;32m---> 27\u001b[0m     embed \u001b[38;5;241m=\u001b[39m bert_model(\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embed\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "df_clean_chunks['vector'] = df_clean_chunks['tokens'].progress_apply(vectorize)\n",
    "df_dirty_chunks['vector'] = df_dirty_chunks['tokens'].progress_apply(vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d9e98-477a-427c-bad5-1c8f2a80171b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94bf43c-86a8-4a55-b740-b5c7121977b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto-pln",
   "language": "python",
   "name": "proyecto-pln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
